{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic_Diwani_OCR_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fnb8t0fmifydgb3I8o3s6RIDi5phXTWY",
      "authorship_tag": "ABX9TyPZyQgGhcGG1gQkpRTcm0pn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed-S-Helal/Arabic-Diwani-OCR/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iJrnlPd0WO3e"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/models1 .\n",
        "!cp -r /content/drive/MyDrive/models2 .\n",
        "!cp -r /content/drive/MyDrive/test .\n",
        "!cp -r /content/drive/MyDrive/truth ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "0rGwCzMBWvyl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import ImageFont\n",
        "from PIL import Image as im\n",
        "from PIL import ImageDraw\n",
        "import io\n",
        "import os\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2 as cv\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import pickle\n",
        "import multiprocessing as mp\n",
        "import re\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.morphology import skeletonize, thin\n",
        "from scipy.ndimage import interpolation as inter"
      ],
      "metadata": {
        "id": "z8OMw66VXfs-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_otsus(image, filter:int=1):\n",
        "    \"\"\"Binarize an image 0's and 255's using Otsu's Binarization\"\"\"\n",
        "\n",
        "    if len(image.shape) == 3:\n",
        "        gray_img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_img = image\n",
        "\n",
        "    # Otsus Binarization\n",
        "    if filter != 0:\n",
        "        blur = cv.GaussianBlur(gray_img, (3,3), 0)\n",
        "        binary_img = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "    else:\n",
        "        binary_img = cv.threshold(gray_img, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "    return binary_img\n",
        "\n",
        "\n",
        "def find_score(arr, angle):\n",
        "    data = inter.rotate(arr, angle, reshape=False, order=0)\n",
        "    hist = np.sum(data, axis=1)\n",
        "    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
        "    return hist, score\n",
        "\n",
        "def deskew(binary_img):\n",
        "    ht, wd = binary_img.shape\n",
        "    # _, binary_img = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
        "\n",
        "    # pix = np.array(img.convert('1').getdata(), np.uint8)\n",
        "    bin_img = (binary_img // 255.0)\n",
        "\n",
        "    delta = 0.1\n",
        "    limit = 3\n",
        "    angles = np.arange(-limit, limit+delta, delta)\n",
        "    scores = []\n",
        "    for angle in angles:\n",
        "        hist, score = find_score(bin_img, angle)\n",
        "        scores.append(score)\n",
        "\n",
        "    best_score = max(scores)\n",
        "    best_angle = angles[scores.index(best_score)]\n",
        "    # print('Best angle: {}'.formate(best_angle))\n",
        "\n",
        "    # correct skew\n",
        "    data = inter.rotate(bin_img, best_angle, reshape=False, order=0)\n",
        "    img = im.fromarray((255 * data).astype(\"uint8\"))\n",
        "\n",
        "    # img.save('skew_corrected.png')\n",
        "    pix = np.array(img)\n",
        "    return pix\n",
        "\n",
        "def vexpand(gray_img, color:int):\n",
        "    \"\"\"Expand the image by some space vertically in both directions\"\"\"\n",
        "\n",
        "    color = 1 if color > 0 else 0\n",
        "    (h, w) = gray_img.shape[:2]\n",
        "    space = np.ones((10, w)) * 255 * color\n",
        "\n",
        "    return np.block([[space], [gray_img], [space]])\n",
        "\n",
        "\n",
        "def hexpand(gray_img, color:int):\n",
        "    \"\"\"Expand the image by some space horizontally in both directions\"\"\"\n",
        "\n",
        "    color = 1 if color > 0 else 0\n",
        "    (h, w) = gray_img.shape[:2]\n",
        "    space = np.ones((h, 10)) * 255 * color\n",
        "\n",
        "    return np.block([space, gray_img, space])\n",
        "\n",
        "def valid(row, col, vis, word):\n",
        "    return (row < vis.shape[0] and col < vis.shape[1] and row >= 0 and col >=0 and vis[row][col] == 0 and word[row][col] > 0)\n",
        "\n",
        "def dfs(row, col, vis, word):\n",
        "    dX = [0,0,1,1,-1,-1,1,-1]\n",
        "    dY = [1,-1,0,1,0,-1,-1,1]\n",
        "    vis[row][col] += 1\n",
        "    for i in range(8):\n",
        "        if(valid(row+dX[i],col+dY[i],vis, word)):\n",
        "            dfs(row+dX[i], col+dY[i], vis, word)\n",
        "    return\n",
        "\n",
        "\n",
        "#utilities\n",
        "\n",
        "def save_image(img, folder, title):\n",
        "    cv.imwrite(f'./{folder}/{title}.png', img)\n",
        "\n",
        "\n",
        "def projection(gray_img, axis:str='horizontal'):\n",
        "    \"\"\" Compute the horizontal or the vertical projection of a gray image \"\"\"\n",
        "\n",
        "    if axis == 'horizontal':\n",
        "        projection_bins = np.sum(gray_img, 1).astype('int32')\n",
        "    elif axis == 'vertical':\n",
        "        projection_bins = np.sum(gray_img, 0).astype('int32')\n",
        "\n",
        "    return projection_bins\n",
        "\n",
        "\n",
        "#segmentation\n",
        "\n",
        "def preprocess(image):\n",
        "    # Maybe we end up using only gray level image.\n",
        "    gray_img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    gray_img = cv.bitwise_not(gray_img)\n",
        "\n",
        "    binary_img = binary_otsus(gray_img, 0)\n",
        "    # cv.imwrite('origin.png', gray_img)\n",
        "\n",
        "    # deskewed_img = deskew(binary_img)\n",
        "    deskewed_img = deskew(binary_img)\n",
        "    # cv.imwrite('output.png', deskewed_img)\n",
        "\n",
        "    # binary_img = binary_otsus(deskewed_img, 0)\n",
        "    # breakpoint()\n",
        "\n",
        "    # Visualize\n",
        "\n",
        "    # breakpoint()\n",
        "    return deskewed_img\n",
        "\n",
        "\n",
        "def projection_segmentation(clean_img, axis, cut=3):\n",
        "    segments = []\n",
        "    start = -1\n",
        "    cnt = 0\n",
        "\n",
        "    projection_bins = projection(clean_img, axis)\n",
        "    for idx, projection_bin in enumerate(projection_bins):\n",
        "\n",
        "        if projection_bin != 0:\n",
        "            cnt = 0\n",
        "        if projection_bin != 0 and start == -1:\n",
        "            start = idx\n",
        "        if projection_bin == 0 and start != -1:\n",
        "            cnt += 1\n",
        "            if cnt >= cut:\n",
        "                if axis == 'horizontal':\n",
        "                    segments.append(clean_img[max(start-1, 0):idx, :])\n",
        "                elif axis == 'vertical':\n",
        "                    segments.append(clean_img[:, max(start-1, 0):idx])\n",
        "                cnt = 0\n",
        "                start = -1\n",
        "    \n",
        "    return segments\n",
        "\n",
        "\n",
        "# Line Segmentation\n",
        "#----------------------------------------------------------------------------------------\n",
        "def line_horizontal_projection(image, cut=3):\n",
        "    # Preprocess input image\n",
        "    clean_img = preprocess(image)\n",
        "\n",
        "\n",
        "    # Segmentation    \n",
        "    lines = projection_segmentation(clean_img, axis='horizontal', cut=cut)\n",
        "\n",
        "    return lines\n",
        "\n",
        "\n",
        "# Word Segmentation\n",
        "#----------------------------------------------------------------------------------------\n",
        "def word_vertical_projection(line_image, cut=3):\n",
        "    line_words = projection_segmentation(line_image, axis='vertical', cut=cut)\n",
        "    line_words.reverse()\n",
        "    \n",
        "    return line_words\n",
        "\n",
        "\n",
        "def extract_words(img, visual=0):\n",
        "    lines = line_horizontal_projection(img)\n",
        "    words = []\n",
        "    \n",
        "    for idx, line in enumerate(lines):\n",
        "        \n",
        "        if visual:\n",
        "            save_image(line, 'lines', f'line{idx}')\n",
        "\n",
        "        line_words = word_vertical_projection(line)\n",
        "        for w in line_words:\n",
        "            # if len(words) == 585:\n",
        "            #     print(idx)\n",
        "            words.append((w, line))\n",
        "        # words.extend(line_words)\n",
        "\n",
        "    # breakpoint()\n",
        "    if visual:\n",
        "        for idx, word in enumerate(words):\n",
        "            save_image(word[0], 'words', f'word{idx}')\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "#character segmentation\n",
        "\n",
        "def binarize(word_img):\n",
        "    _, binary_img = cv.threshold(word_img, 127, 255, cv.THRESH_BINARY)\n",
        "    # _, binary_img = cv.threshold(word_img, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "    return binary_img // 255\n",
        "\n",
        "\n",
        "def fill(binary_img, VP):\n",
        "    (h, w) = binary_img.shape\n",
        "\n",
        "    flag = 1\n",
        "    while flag:\n",
        "        flag = 0\n",
        "        for row in range(h-1):\n",
        "            for col in range(1, w-1):\n",
        "\n",
        "                if binary_img[row][col] == 0 and binary_img[row][col-1] == 1 and binary_img[row][col+1] == 1 and binary_img[row+1][col] == 1 and VP[col] != 0:\n",
        "                    binary_img[row][col] = 1\n",
        "                    # flag = 1\n",
        "\n",
        "    return binary_img\n",
        "    \n",
        "\n",
        "def baseline_detection(word_img):\n",
        "    '''Get baseline index of a given word'''\n",
        "\n",
        "    HP = projection(word_img, 'horizontal')\n",
        "    peak = np.amax(HP)\n",
        "\n",
        "    # Array of indices of max element\n",
        "    baseline_idx = np.where(HP == peak)[0]\n",
        "\n",
        "    # Get first or last index\n",
        "    upper_base = baseline_idx[0]\n",
        "    lower_base = baseline_idx[-1]\n",
        "    thickness = abs(lower_base - upper_base) + 1\n",
        "    \n",
        "    return upper_base, lower_base, thickness\n",
        "\n",
        "\n",
        "def horizontal_transitions(word_img, baseline_idx):\n",
        "    max_transitions = 0\n",
        "    max_transitions_idx = baseline_idx\n",
        "    line_idx = baseline_idx-1\n",
        "    lines = []\n",
        "    # new temp image with no dots above baseline\n",
        "    \n",
        "    while line_idx >= 0:\n",
        "        current_transitions = 0\n",
        "        flag = 0\n",
        "\n",
        "        horizontal_line = word_img[line_idx, :]\n",
        "        for pixel in reversed(horizontal_line):\n",
        "\n",
        "            if pixel == 1 and flag == 0:\n",
        "                current_transitions += 1\n",
        "                flag = 1\n",
        "            elif pixel == 0 and flag == 1:\n",
        "                current_transitions += 1\n",
        "                flag = 0\n",
        "                \n",
        "        if current_transitions >= max_transitions:\n",
        "            max_transitions = current_transitions\n",
        "            lines.append(line_idx)\n",
        "            max_transitions_idx = line_idx\n",
        "\n",
        "        line_idx -= 1\n",
        "    \n",
        "    return lines[len(lines)//2]\n",
        "\n",
        "\n",
        "def vertical_transitions(word_img, cut):\n",
        "    transitions = 0\n",
        "\n",
        "    vertical_line = word_img[:, cut]\n",
        "\n",
        "    flag = 0\n",
        "    for pixel in vertical_line:\n",
        "\n",
        "        if pixel == 1 and flag == 0:\n",
        "            transitions += 1\n",
        "            flag = 1\n",
        "        elif pixel == 0 and flag == 1:\n",
        "            transitions += 1\n",
        "            flag = 0\n",
        "\n",
        "    return transitions\n",
        "\n",
        "\n",
        "def cut_points(word_img, VP, MFV, MTI, baseline_idx):\n",
        "    # flag to know the start of the word\n",
        "    f = 0\n",
        "\n",
        "    flag = 0\n",
        "    (h, w) = word_img.shape\n",
        "    i = w-1\n",
        "    separation_regions = []\n",
        "\n",
        "    wrong = 0\n",
        "    # loop over the width of the image from right to left\n",
        "    while i >= 0:\n",
        "\n",
        "        pixel = word_img[MTI, i]\n",
        "        \n",
        "        if pixel == 1 and f == 0:\n",
        "            f = 1\n",
        "            flag = 1\n",
        "\n",
        "        if f == 1:\n",
        "\n",
        "            # Get start and end of separation region (both are black pixels <----)\n",
        "            if pixel == 0 and flag == 1:\n",
        "                start = i+1\n",
        "                flag = 0\n",
        "            elif pixel == 1 and flag == 0:\n",
        "                end = i         # end maybe = i not i+1\n",
        "                flag = 1\n",
        "\n",
        "                mid = (start + end) // 2\n",
        "\n",
        "                left_zero = -1\n",
        "                left_MFV = -1\n",
        "                right_zero = -1\n",
        "                right_MFV = -1\n",
        "                # threshold for MFV\n",
        "                T = 1\n",
        "\n",
        "                j = mid - 1\n",
        "                # loop from mid to end to get nearest VP = 0 and VP = MFV\n",
        "                while j >= end:\n",
        "                    \n",
        "                    if VP[j] == 0 and left_zero == -1:\n",
        "                        left_zero = j\n",
        "                    if VP[j] <= MFV + T and left_MFV == -1:\n",
        "                        left_MFV = j\n",
        "\n",
        "                    # if left_zero != -1 and left_MFV != -1:\n",
        "                    #     break\n",
        "\n",
        "                    j -= 1\n",
        "\n",
        "                j = mid\n",
        "                # loop from mid to start to get nearest VP = 0 and VP = MFV\n",
        "                while j <= start:\n",
        "\n",
        "                    if VP[j] == 0 and right_zero == -1:\n",
        "                        right_zero = j\n",
        "                    if VP[j] <= MFV + T and right_MFV == -1:\n",
        "                        right_MFV = j\n",
        "\n",
        "                    if right_zero != -1 and right_MFV != -1:\n",
        "                        break\n",
        "\n",
        "                    j += 1\n",
        "\n",
        "                # Check for VP = 0 first\n",
        "                if VP[mid] == 0:\n",
        "                    cut_index = mid\n",
        "                elif left_zero != -1 and right_zero != -1:\n",
        "                    \n",
        "                    if abs(left_zero-mid) <= abs(right_zero-mid):\n",
        "                        cut_index = left_zero\n",
        "                    else:\n",
        "                        cut_index = right_zero\n",
        "                elif left_zero != -1:\n",
        "                    cut_index = left_zero\n",
        "                elif right_zero != -1:\n",
        "                    cut_index = right_zero\n",
        "\n",
        "                # Check for VP = MFV second\n",
        "                # elif VP[mid] <= MFV+T:\n",
        "                #     cut_index = mid\n",
        "                elif left_MFV != -1:\n",
        "                    cut_index = left_MFV\n",
        "                elif right_MFV != -1:\n",
        "                    cut_index = right_MFV\n",
        "                else:\n",
        "                    cut_index = mid\n",
        "\n",
        "\n",
        "                seg = word_img[:, end:start]\n",
        "                HP = projection(seg, 'horizontal')\n",
        "                SHPA = np.sum(HP[:MTI])\n",
        "                SHPB = np.sum(HP[MTI+1:])\n",
        "                \n",
        "                top = 0\n",
        "                for idx, proj in enumerate(HP):\n",
        "                    if proj != 0:\n",
        "                        top = idx\n",
        "                        break\n",
        "\n",
        "                cnt = 0\n",
        "                for k in range(end, cut_index+1):\n",
        "                    if vertical_transitions(word_img, k) > 2:\n",
        "                        cnt = 1\n",
        "                if SHPB == 0 and (baseline_idx - top) <= 5 and cnt == 1:\n",
        "                    # breakpoint()\n",
        "                    wrong = 1\n",
        "                else:\n",
        "                    separation_regions.append((end, cut_index, start))\n",
        "\n",
        "        i -= 1\n",
        "\n",
        "    return separation_regions, wrong\n",
        "\n",
        "\n",
        "def check_baseline(word_img, start, end, upper_base, lower_base):\n",
        "    j = end+1\n",
        "\n",
        "    cnt = 0\n",
        "    while j < start:\n",
        "    \n",
        "        # Black pixel (Discontinuity)\n",
        "        base = upper_base\n",
        "        while base <= lower_base:\n",
        "            \n",
        "            pixel = word_img[base][j]\n",
        "            cnt += pixel\n",
        "\n",
        "            base += 1\n",
        "        \n",
        "        j += 1\n",
        "\n",
        "    if cnt == 0:\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def inside_hole(word_img, end_idx, start_idx):\n",
        "    '''Check if a segment has a hole or not'''\n",
        "\n",
        "    if end_idx == 0 and start_idx == 0:\n",
        "        return 0\n",
        "\n",
        "    sk = skeletonize(word_img)\n",
        "    j = end_idx + 1\n",
        "    flag = 1\n",
        "    while j < start_idx:\n",
        "        VT = vertical_transitions(sk, j)\n",
        "        if VT <= 2:\n",
        "            flag = 0\n",
        "            break\n",
        "        j += 1\n",
        "    \n",
        "    return flag\n",
        "\n",
        "\n",
        "def check_hole(segment):\n",
        "    '''Check if a segment has a hole or not'''\n",
        "\n",
        "    # no_dots = segment.copy()\n",
        "\n",
        "    contours, hierarchy = cv.findContours(segment, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
        "    cnt = 0\n",
        "    for hier in hierarchy[0]:\n",
        "        if hier[3] >= 0:\n",
        "            cnt += 1\n",
        "\n",
        "    return cnt != 0\n",
        "\n",
        "\n",
        "def remove_dots(word_img, threshold=11):\n",
        "    no_dots = word_img.copy()\n",
        "\n",
        "    components, labels, stats, GoCs = cv.connectedComponentsWithStats(no_dots, connectivity=8)\n",
        "    char = []\n",
        "    for label in range(1, components):\n",
        "        _, _, _, _, size = stats[label]\n",
        "        if size > threshold:\n",
        "            char.append(label)\n",
        "    for label in range(1, components):\n",
        "        _, _, _, _, size = stats[label]\n",
        "        if label not in  char:\n",
        "            no_dots[labels == label] = 0\n",
        "\n",
        "    return no_dots\n",
        "\n",
        "\n",
        "def check_dots(segment):\n",
        "    contours, hierarchy = cv.findContours(segment[:, 1:segment.shape[1]-1], cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    cnt = 0\n",
        "    for c in contours:\n",
        "        if len(c) >= 1:\n",
        "            cnt +=1 \n",
        "    return cnt > 1\n",
        "\n",
        "\n",
        "def check_stroke(no_dots_copy, segment, upper_base, lower_base, SR1, SR2):\n",
        "    T = 1\n",
        "    components, labels, stats, cen= cv.connectedComponentsWithStats(segment, connectivity=8)\n",
        "    skeleton = skeletonize(segment.copy()).astype(np.uint8)\n",
        "    (h, w) = segment.shape\n",
        "\n",
        "    cnt = 0\n",
        "    for label in range(1, components):\n",
        "        if stats[label][4] > 3:\n",
        "            cnt += 1\n",
        "        else:\n",
        "            segment[labels==label] = 0\n",
        "\n",
        "    if cnt > 2 or cnt == 0:\n",
        "        return False\n",
        "\n",
        "    if check_hole(segment) or inside_hole(no_dots_copy, SR1[0], SR1[1]) or inside_hole(no_dots_copy, SR2[0], SR2[1]):\n",
        "        return False\n",
        "\n",
        "    HP = projection(skeleton, 'horizontal')\n",
        "    VP = projection(segment, 'vertical')\n",
        "\n",
        "    seg_l = -1\n",
        "    seg_r = -1\n",
        "    for i in range(0, len(VP)):\n",
        "        if VP[i] != 0:\n",
        "            seg_l = i\n",
        "            break\n",
        "    for i in range(len(VP)-1, -1, -1):\n",
        "        if VP[i] != 0:\n",
        "            seg_r = i\n",
        "            break\n",
        "\n",
        "    seg_width = seg_r - seg_l + 1\n",
        "    SHPA = np.sum(HP[:upper_base])\n",
        "    SHPB = np.sum(HP[lower_base+T+1:])\n",
        "    MFV_HP = np.argmax(np.bincount(HP)[1:])+1\n",
        "    MFV = lower_base - upper_base + 1 + T\n",
        "\n",
        "    top_pixel = -1\n",
        "    for i, proj in enumerate(HP):\n",
        "        if proj != 0:\n",
        "            top_pixel = i\n",
        "            break\n",
        "    height = upper_base-top_pixel\n",
        "    \n",
        "    VT = 0\n",
        "    for i in range(w):\n",
        "        if vertical_transitions(skeleton, i) > 2:\n",
        "            VT += 1\n",
        "    cnt = 0\n",
        "    for proj in VP:\n",
        "        if proj >= height:\n",
        "            cnt += 2\n",
        "        elif proj == height-1:\n",
        "            cnt += 1\n",
        "    # abs(MFV - MFV_HP) <= 2\n",
        "    if SHPB == 0  and height <= 6 and VT <= 2 and seg_width <= 6 and cnt >= 2:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def filter_regions(word_img, no_dots_copy, SRL:list, VP:list, upper_base:int, lower_base:int, MTI:int, MFV:int, top_line:int):\n",
        "    valid_separation_regions = []\n",
        "    overlap = []\n",
        "\n",
        "    T = 1\n",
        "    components, labels= cv.connectedComponents(word_img[:lower_base+5, :], connectivity=8)\n",
        "\n",
        "    SR_idx = 0\n",
        "    while SR_idx < len(SRL):\n",
        "        \n",
        "        SR = SRL[SR_idx]\n",
        "        end_idx, cut_idx, start_idx = SR\n",
        "\n",
        "        # Case 1 : Vertical Projection = 0\n",
        "        if VP[cut_idx] == 0:\n",
        "            valid_separation_regions.append(SR)\n",
        "            SR_idx += 1\n",
        "            continue\n",
        "\n",
        "      # Case 2 : no connected path between start and end\n",
        "        # components, labels= cv.connectedComponents(word_img[:, end_idx:start_idx+1], connectivity=8)\n",
        "        if labels[MTI, end_idx] != labels[MTI, start_idx]:\n",
        "            valid_separation_regions.append(SR)\n",
        "            overlap.append(SR)\n",
        "            SR_idx += 1\n",
        "            continue\n",
        "\n",
        "      \n",
        "\n",
        "        # Case 3 : Contain Holes\n",
        "        # if check_hole(no_dots_copy[:, end_idx: cut_idx]) and inside_hole(no_dots_copy, end_idx, start_idx):\n",
        "        cc, l = cv.connectedComponents(1-(no_dots_copy[:, end_idx:start_idx+1]), connectivity=4)\n",
        "        \n",
        "        if cc-1 >= 3 and inside_hole(no_dots_copy, end_idx, start_idx):\n",
        "            SR_idx += 1\n",
        "            continue\n",
        "       \n",
        "     \n",
        "        # Case 4 : No baseline between start and end\n",
        "        segment = no_dots_copy[:, end_idx+1: start_idx]\n",
        "        segment_width = start_idx-end_idx-1\n",
        "\n",
        "        j = end_idx+1\n",
        "        cnt = 0\n",
        "        while j < start_idx:\n",
        "            \n",
        "            # Black pixel (Discontinuity)\n",
        "            base = upper_base-T\n",
        "            while base <= lower_base+T:\n",
        "                \n",
        "                pixel = no_dots_copy[base][j]\n",
        "                cnt += pixel\n",
        "\n",
        "                base += 1\n",
        "            \n",
        "            j += 1\n",
        "\n",
        "        if cnt < segment_width-2 and segment_width > 4:\n",
        "            \n",
        "            segment_HP = projection(segment, 'horizontal')\n",
        "\n",
        "            SHPA = np.sum(segment_HP[:upper_base])\n",
        "            SHPB = np.sum(segment_HP[lower_base+T+1:])\n",
        "\n",
        "            if (int(SHPB) - int(SHPA)) >= 0:\n",
        "                SR_idx += 1\n",
        "                continue\n",
        "            elif VP[cut_idx] <= MFV + T:\n",
        "                valid_separation_regions.append(SR)\n",
        "                SR_idx += 1\n",
        "                continue\n",
        "            else:\n",
        "                SR_idx += 1\n",
        "                continue\n",
        "\n",
        "      \n",
        "        # if SR_idx == 0:\n",
        "        #     breakpoint()\n",
        "        # Case 5 : Last region or next VP[nextcut] = 0\n",
        "        if SR_idx == len(SRL) - 1 or VP[SRL[SR_idx+1][1]] == 0:\n",
        "\n",
        "            if SR_idx == len(SRL) - 1:\n",
        "                segment_dots = word_img[:, :SRL[SR_idx][1]+1]\n",
        "                segment = no_dots_copy[:, :SRL[SR_idx][1]+1]\n",
        "                next_cut = 0\n",
        "            else:\n",
        "                next_cut = SRL[SR_idx+1][1]\n",
        "                segment_dots = word_img[:, next_cut:SRL[SR_idx][1]+1]\n",
        "                segment = no_dots_copy[:, next_cut:SRL[SR_idx][1]+1]\n",
        "\n",
        "            segment_HP = projection(segment, 'horizontal')\n",
        "            (h, w) = segment.shape\n",
        "\n",
        "            top = -1\n",
        "            for i, proj in enumerate(segment_HP):\n",
        "                if proj != 0:\n",
        "                    top = i\n",
        "                    break\n",
        "            height = upper_base - top\n",
        "\n",
        "            # if SR_idx == len(SRL) - 1:\n",
        "                # breakpoint()\n",
        "            SHPA = np.sum(segment_HP[:upper_base])\n",
        "            SHPB = np.sum(segment_HP[lower_base+T+1:])\n",
        "            sk = skeletonize(segment).astype(np.uint8)\n",
        "            seg_VP = projection(segment, 'vertical')\n",
        "            non_zero =  np.nonzero(seg_VP)[0]\n",
        "            cnt = 0\n",
        "            # for k in range(0, (len(non_zero)//2)+(len(non_zero)%2)):\n",
        "            for k in range(0, 3):\n",
        "                if k >= len(non_zero):\n",
        "                    break\n",
        "                index = non_zero[k]\n",
        "                if seg_VP[index] >= height:\n",
        "                    cnt += 1\n",
        "            \n",
        "            if (SHPB <= 5 and cnt > 0 and height <= 6) or (len(non_zero) >= 10 and SHPB > SHPA and not check_dots(segment_dots)):\n",
        "                SR_idx += 1\n",
        "                continue\n",
        "                \n",
        "        # Strokes \n",
        "\n",
        "        SEGP = (-1, -1)\n",
        "        SEG = (-1, -1)\n",
        "        SEGN = (-1, -1)\n",
        "        SEGNN = (-1, -1)\n",
        "        SEGP_SR1 = (0, 0)\n",
        "        SEGP_SR2 = (0, 0)\n",
        "        SEG_SR1 = (0, 0)\n",
        "        SEG_SR2 = (0, 0)\n",
        "        SEGN_SR1 = (0, 0)\n",
        "        SEGN_SR2 = (0, 0)\n",
        "        SEGNN_SR1 = (0, 0)\n",
        "        SEGNN_SR2 = (0, 0)\n",
        "\n",
        "        current_cut = SR[1]\n",
        "     \n",
        "        if SR_idx == 0:\n",
        "            SEGP = (SRL[SR_idx][1], word_img.shape[1]-1)\n",
        "            SEGP_SR1 = (SRL[SR_idx][0], SRL[SR_idx][2])\n",
        "            SEGP_SR2 = (SRL[SR_idx][1], word_img.shape[1]-1)\n",
        "\n",
        "        if SR_idx > 0:\n",
        "            SEGP = (SRL[SR_idx][1], SRL[SR_idx-1][1])\n",
        "            SEGP_SR1 = (SRL[SR_idx][0], SRL[SR_idx][2])\n",
        "            SEGP_SR2 = (SRL[SR_idx-1][0], SRL[SR_idx-1][2])\n",
        "        \n",
        "        if SR_idx < len(SRL)-1:\n",
        "            SEG = (SRL[SR_idx+1][1], SRL[SR_idx][1])\n",
        "            SEG_SR1 = (SRL[SR_idx][0], SRL[SR_idx][2])\n",
        "            SEG_SR2 = (SRL[SR_idx+1][0], SRL[SR_idx+1][2])\n",
        "\n",
        "        if SR_idx < len(SRL)-2:\n",
        "            SEGN = (SRL[SR_idx+2][1], SRL[SR_idx+1][1])\n",
        "            SEGN_SR1 = (SRL[SR_idx+1][0], SRL[SR_idx+1][2])\n",
        "            SEGN_SR2 = (SRL[SR_idx+2][0], SRL[SR_idx+2][2])\n",
        "        elif SR_idx == len(SRL)-2:\n",
        "            SEGN = (0, SRL[SR_idx+1][1])\n",
        "            SEGN_SR1 = (SRL[SR_idx+1][0], SRL[SR_idx+1][2])\n",
        "            SEGN_SR2 = (0, SRL[SR_idx+1][2])\n",
        "\n",
        "            \n",
        "        if SR_idx < len(SRL)-3:\n",
        "            SEGNN = (SRL[SR_idx+3][1], SRL[SR_idx+2][1])\n",
        "            SEGNN_SR1 = (SRL[SR_idx+2][0], SRL[SR_idx+2][2])\n",
        "            SEGNN_SR2 = (SRL[SR_idx+3][0], SRL[SR_idx+3][2])\n",
        "\n",
        "        # SEG is stroke with dots\n",
        "        if SEG[0] != -1 and\\\n",
        "            (check_stroke(no_dots_copy, no_dots_copy[:, SEG[0]:SEG[1]], upper_base, lower_base, SEG_SR1, SEG_SR2) \\\n",
        "            and check_dots(word_img[:, SEG[0]:SEG[1]])):\n",
        "            \n",
        "            # Case when starts with ش\n",
        "            if SEGP[0] != -1 and \\\n",
        "                ((check_stroke(no_dots_copy, no_dots_copy[:, SEGP[0]:SEGP[1]], upper_base, lower_base, SEGP_SR1, SEGP_SR2) \\\n",
        "                and not check_dots(word_img[:, SEGP[0]:SEGP[1]]))\\\n",
        "                and (SR_idx == 0 or VP[SRL[SR_idx-1][1]] == 0 or (VP[SRL[SR_idx-1][1]] == 0 and SRL[SR_idx-1] in overlap))):\n",
        "                \n",
        "                SR_idx += 2\n",
        "                continue\n",
        "            else:\n",
        "                valid_separation_regions.append(SR)\n",
        "                SR_idx += 1\n",
        "                continue\n",
        "                \n",
        "        # SEG is stroke without dots\n",
        "        elif SEG[0] != -1\\\n",
        "            and (check_stroke(no_dots_copy, no_dots_copy[:, SEG[0]:SEG[1]], upper_base, lower_base, SEG_SR1, SEG_SR2) \\\n",
        "            and not check_dots(word_img[:, SEG[0]:SEG[1]])):\n",
        "\n",
        "            # Case starts with س\n",
        "            if SEGP[0] != -1\\\n",
        "                and (check_stroke(no_dots_copy, no_dots_copy[:, SEGP[0]:SEGP[1]], upper_base, lower_base, SEGP_SR1, SEGP_SR2) \\\n",
        "                and not check_dots(word_img[:, SEGP[0]:SEGP[1]])):\n",
        "\n",
        "                SR_idx += 2\n",
        "                continue\n",
        "\n",
        "            # SEGN is stroke without dots\n",
        "            if SEGN[0] != -1 \\\n",
        "                and (check_stroke(no_dots_copy, no_dots_copy[:, SEGN[0]:SEGN[1]], upper_base, lower_base, SEGN_SR1, SEGN_SR2) \\\n",
        "                and not check_dots(word_img[:, SEGN[0]:SEGN[1]])):\n",
        "\n",
        "                valid_separation_regions.append(SR)\n",
        "                SR_idx += 3\n",
        "                continue\n",
        "\n",
        "            # SEGN stroke with Dots and SEGNN stroke without Dots\n",
        "            if SEGN[0] != -1\\\n",
        "                and (check_stroke(no_dots_copy, no_dots_copy[:, SEGN[0]:SEGN[1]], upper_base, lower_base, SEGN_SR1, SEGN_SR2) \\\n",
        "                and check_dots(word_img[:, SEGN[0]:SEGN[1]])) \\\n",
        "                and ((SEGNN[0] != -1 \\\n",
        "                and (check_stroke(no_dots_copy, no_dots_copy[:, SEGNN[0]:SEGNN[1]], upper_base, lower_base, SEGNN_SR1, SEGNN_SR2) \\\n",
        "                and not check_dots(word_img[:, SEGNN[0]:SEGNN[1]]))) or (len(SRL)-1-SR_idx == 2) or (len(SRL)-1-SR_idx == 3)):\n",
        "        \n",
        "                    valid_separation_regions.append(SR)\n",
        "                    SR_idx += 3\n",
        "                    continue\n",
        "            \n",
        "            # SEGN is not stroke or Stroke with Dots\n",
        "            if SEGN[0] != -1 \\\n",
        "                and ((not check_stroke(no_dots_copy, no_dots_copy[:, SEGN[0]:SEGN[1]], upper_base, lower_base, SEGN_SR1, SEGN_SR2)) \\\n",
        "                or (check_stroke(no_dots_copy, no_dots_copy[:, SEGN[0]:SEGN[1]], upper_base, lower_base, SEGN_SR1, SEGN_SR2) \\\n",
        "                and check_dots(word_img[:, SEGN[0]:SEGN[1]]))):\n",
        "                    \n",
        "                    SR_idx += 1\n",
        "                    continue\n",
        "            \n",
        "            SR_idx += 1\n",
        "            continue\n",
        "                \n",
        "\n",
        "        if (len(valid_separation_regions) == 0 or\\\n",
        "            len(valid_separation_regions) > 0 and abs(cut_idx-valid_separation_regions[-1][1]) > 2): \n",
        "            valid_separation_regions.append(SR)\n",
        "        SR_idx += 1\n",
        "\n",
        "    return valid_separation_regions\n",
        "\n",
        "\n",
        "def extract_char(img, valid_SR):\n",
        "\n",
        "    # binary image needs to be (0, 255) to be saved on disk not (0, 1)\n",
        "    img = img * 255\n",
        "    h, w = img.shape\n",
        "\n",
        "    next_cut = w\n",
        "    char_imgs = []\n",
        "\n",
        "    for SR in valid_SR:\n",
        "        char_imgs.append(img[:, SR[1]:next_cut])\n",
        "        next_cut = SR[1]\n",
        "    char_imgs.append(img[:, 0:next_cut])\n",
        "\n",
        "    return char_imgs\n",
        "\n",
        "\n",
        "def segment(line, word_img):\n",
        "    # binary_word = binarize(word_img)\n",
        "    binary_word = word_img//255\n",
        "    no_dots_copy = remove_dots(binary_word)\n",
        "\n",
        "    # l = binary_word.copy()\n",
        "\n",
        "    VP_no_dots = projection(no_dots_copy, 'vertical')\n",
        "    VP = projection(binary_word, 'vertical')\n",
        "    binary_word = fill(binary_word, VP_no_dots)\n",
        "    no_dots_copy = remove_dots(binary_word)\n",
        "\n",
        "    # sk = skeletonize(no_dots_copy)\n",
        "    upper_base, lower_base, MFV = baseline_detection(remove_dots(line))\n",
        "    MTI = horizontal_transitions(no_dots_copy, upper_base)\n",
        "        \n",
        "    SRL, wrong = cut_points(binary_word, VP, MFV, MTI, upper_base)\n",
        "\n",
        "    if wrong:\n",
        "        MTI -= 1\n",
        "        SRL.clear()\n",
        "        SRL, wrong = cut_points(binary_word, VP, MFV, MTI, upper_base)\n",
        "\n",
        "    HP = projection(line, 'horizontal')\n",
        "    top_line = -1\n",
        "\n",
        "    valid = filter_regions(binary_word, no_dots_copy, SRL, VP, upper_base, lower_base, MTI, MFV, top_line)\n",
        "\n",
        "    chars = extract_char(binary_word, valid)\n",
        "\n",
        "    return chars\n",
        "\n",
        "def bound_box(img_char):\n",
        "    HP = projection(img_char, 'horizontal')\n",
        "    VP = projection(img_char, 'vertical')\n",
        "\n",
        "    top = -1\n",
        "    down = -1\n",
        "    left = -1\n",
        "    right = -1\n",
        "\n",
        "    i = 0\n",
        "    while i < len(HP):\n",
        "        if HP[i] != 0:\n",
        "            top = i\n",
        "            break\n",
        "        i += 1\n",
        "\n",
        "    i = len(HP)-1\n",
        "    while i >= 0:\n",
        "        if HP[i] != 0:\n",
        "            down = i\n",
        "            break\n",
        "        i -= 1\n",
        "\n",
        "    i = 0\n",
        "    while i < len(VP):\n",
        "        if VP[i] != 0:\n",
        "            left = i\n",
        "            break\n",
        "        i += 1\n",
        "\n",
        "    i = len(VP)-1\n",
        "    while i >= 0:\n",
        "        if VP[i] != 0:\n",
        "            right = i\n",
        "            break\n",
        "        i -= 1\n",
        "\n",
        "    return img_char[top:down+1, left:right+1]"
      ],
      "metadata": {
        "id": "a-t5HBZudYmg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 40\n",
        "height = 40\n",
        "dim = (width, height)\n",
        "\n",
        "def prepare_char(char_img):\n",
        "\n",
        "    binary_char = binarize(char_img)\n",
        "\n",
        "    try:\n",
        "        char_box = bound_box(binary_char)\n",
        "        resized = cv.resize(char_box, dim, interpolation = cv.INTER_AREA)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return resized\n",
        "\n",
        "\n",
        "def featurizer(char_img):\n",
        "\n",
        "    flat_char = char_img.flatten()\n",
        "\n",
        "    return flat_char\n",
        "\n",
        "def run2(obj):\n",
        "    word, line = obj\n",
        "    model = load_model()\n",
        "    # For each word in the image\n",
        "    char_imgs = segment(line, word)\n",
        "    txt_word = ''\n",
        "    # For each character in the word\n",
        "    for char_img in char_imgs:\n",
        "        try:\n",
        "            ready_char = prepare_char(char_img)\n",
        "        except:\n",
        "            continue\n",
        "        feature_vector = featurizer(ready_char)\n",
        "        predicted_char = model.predict([feature_vector])[0]\n",
        "        txt_word += predicted_char\n",
        "    return txt_word\n",
        "\n",
        "def run(image_path, model):\n",
        "    # Read test image\n",
        "    full_image = cv.imread(image_path)\n",
        "    predicted_text = ''\n",
        "\n",
        "    # Start Timer\n",
        "    before = time.time()\n",
        "    words = extract_words(full_image)       # [ (word, its line),(word, its line),..  ]\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    predicted_words = pool.map(run2, words)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    # Stop Timer\n",
        "    after = time.time()\n",
        "\n",
        "    # append in the total string.\n",
        "    for word in predicted_words:\n",
        "        predicted_text += word\n",
        "        predicted_text += ' '\n",
        "\n",
        "    exc_time = after-before\n",
        "    # Create file with the same name of the image\n",
        "    img_name = image_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "    with open(f'output/{model}/text/{img_name}.txt', 'w+', encoding='utf8') as fo:\n",
        "        print(\"predicted_text:\",predicted_text)\n",
        "        fo.writelines(predicted_text)\n",
        "\n",
        "    return (img_name, exc_time)\n"
      ],
      "metadata": {
        "id": "uVcQ7hpItYl3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "    print(model)\n",
        "    if not os.path.exists(f'output/{model}'):\n",
        "        os.makedirs(f'output/{model}')\n",
        "    open(f'output/{model}/running_time.txt', 'w+').close()\n",
        "\n",
        "    destination = f'output/{model}/text'\n",
        "    if not os.path.exists(destination):\n",
        "        os.makedirs(destination)\n",
        "\n",
        "    types = ['png', 'jpg', 'bmp']\n",
        "    images_paths = []\n",
        "    for t in types:\n",
        "        images_paths.extend(glob(f'test/*.{t}'))\n",
        "    before = time.time()\n",
        "\n",
        "    running_time = []\n",
        "    print(\"images_paths:\", images_paths)\n",
        "    for images_path in tqdm(images_paths,total=len(images_paths)):\n",
        "        running_time.append(run(images_path, model))\n",
        "\n",
        "    print(\"running_times:\", running_time)\n",
        "\n",
        "    running_time.sort()\n",
        "    with open(f'output/{model}/running_time.txt', 'w+') as r:\n",
        "        for t in running_time:\n",
        "            r.writelines(f'image#{t[0]}: {t[1]}\\n')       # if no need for printing 'image#id'.\n",
        "            \n",
        "        after = time.time()\n",
        "        print(f'total time to finish {len(images_paths)} images:')\n",
        "        print(after - before)"
      ],
      "metadata": {
        "id": "4vjh6OJIWlpl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = 'models1'"
      ],
      "metadata": {
        "id": "peoGMux4Pa9-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '1L_NN'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "\n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDrIyMcEhWft",
        "outputId": "cb767230-5106-4f63-bc05-687ccb4d36cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1L_NN\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:01<00:03,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا و ما حعمم عنا خ ا وناظ دلض تصا ضي يك \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:03,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا ظاطح غيا بي حغ ا دتا كجا ضهف \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:02<00:04,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ما خاننا ضن ا ضضا دما راح خعم دضا خق جضا تجا بكا ضنكا را عنظحض \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:02<00:02,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:10<00:13,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ااهضاا اتننتيات اتظاصهط ممت اتنصم اهبت اتهنام ااتنااب ها انت اتنجه هح اظظح نوبم انتي نح ذاح ت اهعهاام اق هي ت مجلا اهههتات زا ههض اههضب اههف نب اهظاضمف همننس غثح هم اضانت همم اظضمت هت انب نم اظهت همنمنا نا جقق النصا نقا تنام نم اطب اهجهاات نت نض الظاس ظصه نهت اهنما هت اااي نهمي اتام ه اجطهي سنضاواي ذاهاا مت ها ضلبق اههي قاه نضااجي اهنناات هاهقنمس ههخضلاات ههت اهاب اهباضام هههض اتشهت ااتشقت اتنانقا اها نت ضهاو اهظي هت اهظي نزهي اقنم ثي زات ه هلطف اتاف ننام ااتننام طا اتتق ههنم اتاطهت هبت اتقاط هههت اننمت منا هتق اثهنا ا هااط قتمي اهت هااما ا هنهني مت هناو تي نان اصقن ههم هها اهها امهت يتا هظطا ه ت هظام هب طتن نقتا ا هان يظاطهشب نت نض هانا ا هظشتب انا اتظاضهط هبم اتهنام ااتنااب ااتامص اضهضهصا ضاضام ثننامض اتنهان اقااا اتثباط ااتظمضات اتاضهط اتدهب ههننا انم ههقن انا نمح اتن هغن قح ضضاح الهم نح اهظم نوبح اهتي عت تتتنا غصت ضيح تتن ضنا ناحم تتح اضهاتح اهم نهن ههان هتب اننه نت ذااما اانها نم باا نها ضاق ت ضهات هاظس هح ظظظح نومح اههم نات هتضات نم اجب انض نت ااظا ه نملا اظت هاي اهات هاههي نم تهن انههي اضات ت مبضنا نم اهطمم مههنهام اههات نقظههات امني ان هاههقا نت هقتضت بهظنهات نجنهام منس هاا اهههمت اس ازا طهن ااهقانض نهمم اخا خذات اتاف اهسنق اتنبهت \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:10<00:07,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:10<00:04,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:11<00:02,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا ضنا خ عنم ا ضاظق ا زا قان ي جدا زجرمصا ظ رامن ي \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:11<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:15<00:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: مب اتظهضماا اتظننبنق هاقلهان نهظاجقا هظضا اهما اتانمان اتقننق نضات ناغقا هااه اتان نانل اتنشنهق هقههم قنا قطهاض هزمنت هن غضاوهاا هاات نااصا الهض اتظااه اظنعاع تهض اتذنم اهطظام ضذاوهات همام اضاض اتتناق تتحاف هاهق ننههن اناهم اتهمال اتهناق تتامات هتهضمب اهمط ماهق اتطاهاش اهمبم غب نااق اتااض تضا اتغب مبم هااض ااتههب اناجط نب ناااح اتانماب اتمام مب جاان طضممه تثض اوبن اتلسب ههات نم هااب اههم نم اناب ظااي انظاهظب اتمام طيخ ههامخات غب لااقه اتلضا اتظهس تتنلم تباث عم انضهغ اارقتاا اظثهت اظنهش ههاث خف قال بنهن بقهطضف هناشقي رهضس مظت ضنم انام بنهعبضب اراظم اههاضهنب اظااي ن اهمق \n",
            "running_times: [('Diwani_Letter_55280', 0.15592265129089355), ('Diwani_Letter_88451', 0.21001267433166504), ('Diwani_Letter_3046', 0.7176573276519775), ('Diwani_Letter_10999', 0.480682373046875), ('Diwani_Letter_2165', 0.9482448101043701), ('Diwani_Letter_48410', 0.20501995086669922), ('Article1', 7.484662055969238), ('Diwani_Letter_14596', 0.2196497917175293), ('Diwani_Letter_95502', 0.21965360641479492), ('Diwani_Letter_7106', 0.61590576171875), ('Diwani_Letter_56404', 0.1792609691619873), ('Article2', 3.608633041381836)]\n",
            "total time to finish 12 images:\n",
            "15.138421058654785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '2L_NN'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "\n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc_jUst8hqTO",
        "outputId": "4dadcfa0-3e8f-4748-e719-0f43c542d4aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2L_NN\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:01<00:03,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا و ما جعظم عنا خ ا شتان ظضك تضا ضي يك \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:03,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا وعاح ذقا غا خغ ا وتا ديا عضش \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:02<00:04,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ما خاننا ضن ا ظضا دحا غعم غعه حظا سن جنا تبا جكا عمتا صا وغضحص \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:02<00:02,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:11<00:15,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ااطضاا اننضقياا اقثاضضح همق اوضضن اهمن انهناب ااننااب ها اقم اننبب هن اظظح وومم انقس نم ذان ن انعهاان ذن مي ن مضلي اقضهناف ذا اخش اوهضب هظيق ذا اوزاذمح هحضاح ذثن نن اشانن همن اظذمف نف انا نم اظهن همتمضا ضا مقس عللضا اعا فنام نن اطب اقاهاام ضف لض الظاس ثصا ذان اننها هن ااام مضمح انام ه اجضهس منضاوهي ذاهاا ضن ضا ضلان اظزم ذان نضاطهس اهضناهن هاثقنمس اهعضضاان ذمن اهاا اهباكهن هقهض انشنت ااقهنت اقنانذا هها مف ضهان انظم هن اظظس كومح اننس ثح ذان ه ضقطق اناف هنام ااقننام ظا انتح مننن اقاطضت ضمن اقناغ ههمف اننمف منا ضتح اثانا ا ضااط ذقمض اقن هااحا ا هنضنس من ننان نض ذان اينن ذنن يطا ايطا امطن يتا هيتا ه ن ضظان ذب تنن ننقا ا ذان يثاطضضا نق اض ضالن ا ضثضتا انا اقزاضضط همن اقهناب ااننااه ااقامض اضمضضضا ذالام ينقاغض اننهان اقااا اقمباح اانظمضان اتالضح اقمنه ههننا اقن ههقن انا نضم تنن هغل نح ضهان الهح قن اظظح كومم انقس كن تنونا ذصت ذدن تنن ذنا كاون ننم اضنانم هنن تنن ذقان ذنب انضض حن ذااحا ااوها كن باا نضا ضاح ن ضمان نلظح هن ظظظح جومح همنس ذان نوشهن نن طبا اهع من طاظا ه جحلا الن هاي ذهات ضاننم نن تنن انهقح تزان م ضعشنا نف انتمن مهظنهان اوذان ظحوبهان اهنم ان ناهققا نف اقتاق ضمونطان هحننام منح هاا اقهضمن فح يصا تقن اانقانض منمم اظا خذهن اناذ اخضنح انوهمن \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:11<00:08,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:11<00:04,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:12<00:02,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا ضنا خ عنه ا ضاطن ا ها طهص ي جضا اجضحصا ظ خطمف س \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:12<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:16<00:00,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: هي اقثهضمان اقثنضمنس هاقلهان نقظاجقا ضثقق اضمذ انانمان انلاننس نضاا نااقا ذاطب انان ناعل اننشنذح ضقمنس نحا وطماض هضمضف هن ذشاوماا هاهن لاااضا هذظذ اوزااض اظنمام ومض اوذنج اهطظاخ ذشاضضاا هبان اذاذ انوااح ننضاف ضانح ننضضت اهانن اقهضاض انمناح نقطمهن منهضخا انحط هاهح انطاضاض اثمبب ضا ناضح اقااض قضا انضب ضمن هااض اانهضب اناجط اي نااعح انانماا اقمام هي حاان طقمضا قمض اومن انضسا ضضات غم ذهطب اقان غن اهاس ثااس انيهضظب انماب زدخ نهاعضاا ذب نهضحب انلضا اوظاس نقننم تباث عن انذهط ااثقذاا اظضين اظنهض نباث جن ذاط علنل بزنطضط هناضقح ثثذس جظن ضنم اناب اناعمضا اهاظس اثضاضضقي اواان ن اامن \n",
            "running_times: [('Diwani_Letter_55280', 0.14804363250732422), ('Diwani_Letter_88451', 0.2106485366821289), ('Diwani_Letter_3046', 0.7101116180419922), ('Diwani_Letter_10999', 0.485598087310791), ('Diwani_Letter_2165', 0.8333399295806885), ('Diwani_Letter_48410', 0.20001840591430664), ('Article1', 8.504769802093506), ('Diwani_Letter_14596', 0.2085413932800293), ('Diwani_Letter_95502', 0.21344709396362305), ('Diwani_Letter_7106', 0.7190876007080078), ('Diwani_Letter_56404', 0.18535900115966797), ('Article2', 3.901367425918579)]\n",
            "total time to finish 12 images:\n",
            "16.42123794555664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Gaussian_Naive_Bayes'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "        \n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azJoHwQohrKH",
        "outputId": "cf7620a0-1c47-4140-ba85-4867d3a8f562"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian_Naive_Bayes\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:00<00:03,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا م ما يعمم عما ا ا ممام هسي امه مم يم \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:02,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا مهاي مها مم مم ا عاه ميا اهس \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:01<00:03,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ما مامنا اا ا مما قما مام مهم حيا هم حما اها هيا امما ما عمممض \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:02<00:02,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:07<00:10,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: هاهمهه همممممها همماعمم مما همممم هممم همممهم ههماههم ها امم همنمه مم هممم مممم همما مم مهم م هممهههم ما مم م مماا هممممهم ما ممم همهمم هممم مه همماممم ممنمم ممم هم اعهمم ممم همممم هم ممه مم هممم مممممه مه مام اعممه ممه ممهم مم اام همعمههم مم ام همنهم همه مهم ههمما هم هههم مممم همهم ه هعمهي مممهمهي مهمهه مم مه همهم ههمم مهم ممهامي همممههم مهممممم همممممها ممم همام هممهمهم مممم هممما ههممما همماممه ههه مم همهم هممه مم هممم مممم هممي مم مهن ه ماهم هههم مههم ههمممهم مه هممم مممم همامما ممم هممهم هممم همنمم مهه مهم امممه ه ماام مممم امم مهامم ه ماممم ما ممهم مم مهم اممم مهم ياه هياه هممم مهه همهه ه م مهام مه ممم ممما ه مها مماهمعه هم مه مهاا ه ممممم ههه همماعمم ممم همممهم ههماههم ههمهمم هممهممه ماعهم مممهمم همامهم هقهها همممهه ههمممههم هماعمم هممهم ممممه امم مممم ههه ممم ممم همم نم مههم همهم هم هممم مممم هممي مم ممممه ممم مهم ممم ممه مهمم ممم هممهمم ههم امم ممها ممه هممه مم اههمه ههمهه مم مهم مهه مهم م ممهم مممم مم مممم مممم هممم مهم هممهم مم همه همع مم هامه ه مماه همم هاه ممها مهممم مم امم همهمم مههم م مهممه مم همممم مهمممهم هممهم ممممماا اممم هه ممهممه مم هماما مهممماا ممممهم ممم مهه همهممم مم هما امم ههممهاه مممم همه ممهم همام هممام هممهمم \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:07<00:05,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:08<00:03,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:08<00:01,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ا منا م عنم ا مهام ا ما قهم ي مها اهيمما ق عقهم ق \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:08<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:11<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: مه هممهممها همممممام مهمامهم مممهممه مممم همما هماممهم همممام ممها ماممه مهام همهم مامم هممممهم ممممم امه مامهم همممم ما ممهممها مههم مههما همهم هممههم ههممام ممم همماع ههممهم ممهممها همهم همهم هممههم مممهم مههم نممما همههم همممهم هههمهم ممهمهن هممممه ههمم مههم همههمهم هممهم مي مهام همههه ممه همما ممم هاهم ههمهمم همامم مي هههعم هماممهم ههمام مه مههم هممما ممم همما هممهم مماا مم مههه هههم مم امهم ههها هممهممه هممهم ممه هههعمها مه اهاقه هماما همنهم مممام ممام مم هممهم ههمممهه هممها هممهم ممام ما اهم عاما همهامم ماهممم مممم ممم همم همهم امهعممه هيامم همماامني هماام م اممم \n",
            "running_times: [('Diwani_Letter_55280', 0.15328431129455566), ('Diwani_Letter_88451', 0.212113618850708), ('Diwani_Letter_3046', 0.513817548751831), ('Diwani_Letter_10999', 0.2788398265838623), ('Diwani_Letter_2165', 0.6272127628326416), ('Diwani_Letter_48410', 0.2084486484527588), ('Article1', 5.594651222229004), ('Diwani_Letter_14596', 0.2165679931640625), ('Diwani_Letter_95502', 0.22654366493225098), ('Diwani_Letter_7106', 0.42431092262268066), ('Diwani_Letter_56404', 0.18316197395324707), ('Article2', 2.893649101257324)]\n",
            "total time to finish 12 images:\n",
            "11.618181943893433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "location = 'models2'"
      ],
      "metadata": {
        "id": "Ot-fl1LMPpUc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '1L_NN'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "\n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGYgTos-QE0C",
        "outputId": "a3f0e155-fe63-422c-c0d0-5ac184978d83"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1L_NN\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:01<00:03,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ح ر يا مطغه متا ي ح شازه رشح وعا ضه صع \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:03,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ح وااج تلاا غم عخ ح وتا رما وهت \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:02<00:03,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: يا ضثننا زت ح رثا عها مزت خحل مثج عض لمح وما مغح وهغح هح وقريض \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:02<00:02,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:09<00:13,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: احذروا المهلكات التحريش بين الممن وبين البهام والدواب صح ذدن النبي صل الله عليه وسلم نه قال ن الشيطان قد يس ن يعده المصلون في حير العرب ولكن في التحريش بينهم فكل من حرذثل بين اثنين من بني دم ونقل بينهما ما يذي حدهما فهو نمام من حزب الشيطان من شر الناس كما قال النسي صل الله عليه ولخم لا خبركم بشراركم قالوا بل يا ررول االه قال شراركم المشاون بالنميم المفرطون بين الحب الياغون للبر العنت والعنت الملاشقا وصح عن رسول الله صل الله عليه ولنم نه قال لا يدخل الجن نمام والنمام هو الذي ينقل الحديث بين الناس وبين اثنين بما يذي حدهما و يوحش قلبه ذعل صاحبه و صديقه بن يقول له قال ذننك فلان كذا وكذا وفعل كذا وكذا لا ن يكون في ذلك مصلح و فاد كتحذيره من شر يحدث و يترتب وما التحريش بين البهام والدواب والطير وغيرهما فحرام كمناقر الديوك ونطاح الكباش والثيران وتحريش الكلاب بعضها ذلل بعضن وما شبه ذلك وقد نه رسول الله صل الله عليه وسلم عن ذلللا فمن فعل ذلك فهو عاصل لله ورسوله ومن ذلك فساد قلب المر عل زوجها والعط عل سطه لما روي ن رسول للله صل الله عليه وسلم قال ملعون من خبب امر عل زاها و عبدا اعل سطه نعوذ بالله من ذلك ونسله تعال ن يجعلا من الذين يستمعون القول فيتبعون حضنه ولا يجعلنا من الذين يستمعون فيضلون عنه سوا السبيل نه ولي ذلك والقادر عليه وهو يقول الحق ويهدي اللسيل \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:10<00:07,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:10<00:04,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:11<00:02,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ح لثا ي مثل ح رتثن ح رع نكث م ورح رمربمط ش مرعش ص \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:11<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:15<00:00,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: في التصفيات التمهيدي نونديال منتخبنا يتلق ويهز الرشباك الهندي مرات محققا فوزه الول محمد المعمري يتسلم دعو لزيار لليمن بد فعاليات بطول موظفي وزار التجار والمظع لكر القدم اختتام فعاليات سباق ظفار اللروي للهجن بولاي ثمريت انطلاق السباق السنوي للخيول العربي الاصد بولاي الخابور اليوم في دوري الطار لقا القم بين صحار والسيب ومجيس في مواجه الرشباب اليوم في بطول خليجي لكر اليد الرسب يبحث عن فوزه الاول عل حساب كاظم الكويتي اليوم ربع مواجهات في دوركا الدرج الثاس للقدم تبحث عن الفوز والنقاط الثلاث النصر يبحث عن فوز جديد وتعزيز صدارته للقم حعل رضه ومام جمافيره الحلم البحريني يتحول ل حقيق \n",
            "running_times: [('Diwani_Letter_55280', 0.15955877304077148), ('Diwani_Letter_88451', 0.20957636833190918), ('Diwani_Letter_3046', 0.705735445022583), ('Diwani_Letter_10999', 0.37647485733032227), ('Diwani_Letter_2165', 0.8312866687774658), ('Diwani_Letter_48410', 0.21773529052734375), ('Article1', 7.408725738525391), ('Diwani_Letter_14596', 0.21494150161743164), ('Diwani_Letter_95502', 0.21312355995178223), ('Diwani_Letter_7106', 0.7189030647277832), ('Diwani_Letter_56404', 0.18706130981445312), ('Article2', 3.703861951828003)]\n",
            "total time to finish 12 images:\n",
            "15.029415845870972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '2L_NN'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "\n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFAmXB5wQKv8",
        "outputId": "37de3c2c-74d0-49d7-b16b-4553a1db67dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2L_NN\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:00<00:03,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: و ر يا هحغص حتا ث و لمرم رسر زما قح يح \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:03,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: و وااع تبا كا عس و رتا ربا امخ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:02<00:04,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: يا بكصنا زح و رما حخا عحص غحن حرج رم برح زوا حضو اهغح مو وغرصخ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:02<00:02,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:10<00:14,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: احذروا المهلكات التحريش بيز الممن وبين البهام والدواب صح حلن النبي صل الله عليه وسلم نه قال ن الشيطان قد يس ن يعده المصلون في طير العرب ولكن في التحريش بينهم فكل من حرلاثل بين اثنين من بني دم ونقل بينهما ما يذي حدهما فهو نمام من حزب الشيطان من شر الناس كما قال النبي صل الله عليه ولطم لا خبركم بشراركم قالوا بل يا ردول االه قال شراركم المشاون بالنميم المفاطون بين الحب الباغون للبر العنت والعنت الملاشقا وصح عن رسول الله صل الله عليه ولطم نه قال لا يدخل الجن نمام والنمام هو الذي ينقل الحديث بين الناس وبين اثنين بما يذي حدهما و يوحش قلبه حعل صاحبه و صديقه بن يقول له قال تعنك فلان كذا وكذا وفعل كذا وكذا لا ن يكون في ذلك مصلح و فاد كتحذيره من شر يحدث و يترتب وما التحريش بين البهام والدواب والطير وغيرهما فحرام كمناقر الديوك ونطاح الكباش والثيران وتحريش الكلاب بعضها حلل بعضل وما شبه ذلك وقد نه رسول الله صل الله عليه وسلم عن ذلليا فمن فعل ذلك فهو عاصل لله ورسوله ومن ذلك فساد قلب المر عل زوجها والعط عل سطه لما روي ن رسول للله صل الله عليه وسلم قال ملعون من خبب امر عل زمها و عبدا اعل سيه نعوذ بالله من ذلك ونسله تعال ن يجعلا من الذين يستمعون القول فيتبعون حسنه ولا يجعلنا من الذين يستمعون فيضلون عنه سوا السبيل نه ولي ذلك والقادر عليه وهو يقول الحق ويهدي اللسيل \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:10<00:08,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:10<00:04,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:11<00:02,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: و رتا ص حعن و رازل و رظ قاع ي عرح روربرك ط حرجغ ص \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:11<00:00,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:16<00:00,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: في التصفيات التمهيدي نونديال منتخبنا يتلق ويهز اللاشباك الهندي مرات محققا فوزه الول محمد المعمري يتسلم دعو لزيار اليمن بد فعاليات بطول موظفي وزار التجار والماع لكر القدم اختتام فعاليات سباق ظفار الدضوي للهجن بولاي ثمريت انطلاق السباق السنوي للخيول العربي الاصد بولاي الخابور اليوم في دوري الطار لقا القم بين صحار والسيب ومجيس في مواجه اللاشباب اليوم في بطول خليجي لكر اليد الاسب يبحث عن فوزه الاول عل حساب كاظم الكويتي اليوم ربع مواجهات في دوريب الدرج الثاس للقدم تبحث عن الفوز والنقاط الثلاث النصر يبحث عن فوز جديد وتعزيز صدارته للقم معل رضه ومام جماهيره الحلم البحريني يتحول ل حقيق \n",
            "running_times: [('Diwani_Letter_55280', 0.1486802101135254), ('Diwani_Letter_88451', 0.20943188667297363), ('Diwani_Letter_3046', 0.6077606678009033), ('Diwani_Letter_10999', 0.3897733688354492), ('Diwani_Letter_2165', 0.928530216217041), ('Diwani_Letter_48410', 0.20647931098937988), ('Article1', 7.999764919281006), ('Diwani_Letter_14596', 0.22193408012390137), ('Diwani_Letter_95502', 0.2264244556427002), ('Diwani_Letter_7106', 0.7251608371734619), ('Diwani_Letter_56404', 0.18720054626464844), ('Article2', 4.182400465011597)]\n",
            "total time to finish 12 images:\n",
            "16.122347831726074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Gaussian_Naive_Bayes'\n",
        "def load_model():\n",
        "    if os.path.exists(location):\n",
        "        model = pickle.load(open(f'{location}/{model_name}.sav', 'rb'))\n",
        "        return model\n",
        "\n",
        "predict(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYzoaqU9QN_Z",
        "outputId": "36fda14a-a124-4d23-b291-144bce6394cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian_Naive_Bayes\n",
            "images_paths: ['test/Diwani_Letter_55280.png', 'test/Diwani_Letter_88451.png', 'test/Diwani_Letter_3046.png', 'test/Diwani_Letter_10999.png', 'test/Diwani_Letter_2165.png', 'test/Diwani_Letter_48410.png', 'test/Article1.png', 'test/Diwani_Letter_14596.png', 'test/Diwani_Letter_95502.png', 'test/Diwani_Letter_7106.png', 'test/Diwani_Letter_56404.png', 'test/Article2.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:00<00:01,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:00<00:01,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:00<00:02,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ه ل يي ممغه متي ض ه ثههس رسن تها مم مس \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:01<00:02,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ه مهيس قهي سي مق ه متا سيي حمم \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:01<00:02,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: يي سعضثي غم ه رفي ربي سيه غعض ممي مم مثح تهي مسه حغسح مه مفغهغ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:01<00:02,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:07<00:10,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: احذروا المهلكات التحغيش ببن الممن وببن البهام والدواب صج حلن الثبي صن العه علبه وسلم له فال ن الشيطان فد عس ن ييده المصلون سي حهح العرب ولكن في التحريش بهثهم فكل من حرحثه ببن اثقبن من يلي دم وتقل بيتهما ما يني حفهما فهو نغام من حزب الشيطان من شر الثاس كما قال التما صل اعهه علبه ولطم لا خهركم بشرارعم قالوا بث يا رلول اهعه قال شرازكم الغشاون بالتغيم الهفعهون ضبن الحب الباضون للبر العلت والعتت المحسقا وصج عن رسول الهه صل العه كلبه ودطم ته قال لا يدخض الجن ففام والتفام غو الذه يلقل الحذيث فبن الناس وبيت اثتين بفا يذه حدهفا و يوحش قلبه حقض صاحبه و صديقه بن يقول له قال حقنك فلان كذا وكذا وفعض كذا وكذا لا ن يكون في ذلك مصلج و فاد كتحذيري من شر يحدث و يترتب وصا التحريش ببن البهام والدواب والطير وفيرغما فحرام كملافر الدبوك ولطاج الكباش والثيران وتحريش الكلاب بعضها حلل بعفه وصا شبه ذلك وفد نه رسول الهه صل العه علبه وسلم عن ذلللا فغن فعن ذلك فهو عامم لله ورسوله ومن ذلس فصاد فلب المر عل زوجها والعه عل سهه لما ريي ن رسول للعه صل علعه علبه وسلم فال ملعون من خهب امر عل زحها و عبدا اصل ميه قعوذ بالله من ذلس هنسله تعال ن يجعسا فن الذين يستمعون القول ففتبعون حغته ولا يجعلنا من الذين يستغعون فيضلون عته سوا الصبيل ده وسي ذلس والقادر علبه وهو يقول الحف ويهده اللهبض \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:07<00:06,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:08<00:03,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:08<00:01,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: ه رشي ض ممض ه ثاهس ه سي قهع م عثح يمرفضه غ مسجف ك \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:08<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:11<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_text: في التصفبات التمهبدي سولدبال ملتخهنا يتدن ويهز الحسباك الهلدي مرات محققا فوزه الول محغد المعمري يتسلم دعو لزيار عليمن بد فعالبات بطول موظضي وزهر التجار وهلمهع لكر القدم اختتام فعالبات سياق ظفار اللهوه للهجن بولاه ثمرمت افطلاق الصباق السنوه للخفول العربي الامق بولاه الخابور البوم في دوري الطار لقا القم فبن صحار والصبب ومجيس في صواجه الحسباب اليوم في بطول خديمي لكر البد العهي يبحث عن فوزه الاول عل حغاب كاظم الكويتي البوم رمع مواجهات في دورقا الدرح الثات للقدم تبحث من الفوز واللقاط الثلاث التصر يبحث عن فوز جديد وتعزيز صدارته للقم معل رضه ومام جغاغبري الحفم البحريتي يتحول ل حقفق \n",
            "running_times: [('Diwani_Letter_55280', 0.15807437896728516), ('Diwani_Letter_88451', 0.2094738483428955), ('Diwani_Letter_3046', 0.4133262634277344), ('Diwani_Letter_10999', 0.3796534538269043), ('Diwani_Letter_2165', 0.5250976085662842), ('Diwani_Letter_48410', 0.20694661140441895), ('Article1', 5.80646538734436), ('Diwani_Letter_14596', 0.21560454368591309), ('Diwani_Letter_95502', 0.22146368026733398), ('Diwani_Letter_7106', 0.525634765625), ('Diwani_Letter_56404', 0.1835474967956543), ('Article2', 2.8936173915863037)]\n",
            "total time to finish 12 images:\n",
            "11.83766484260559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r 'output' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "FmFnc0akvllE"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}